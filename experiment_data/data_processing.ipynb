{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feaa4496-580c-4d5e-aa44-35ad40ef1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../src')\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import wilcoxon, ranksums\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from utils import temporal_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5492f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('data.mat')['data']\n",
    "# data structure:\n",
    "# 'zscore1' and 'zscore2' are the used keys:\n",
    "# (1, 1)\n",
    "# -> (number of birds = 8, 1) \n",
    "#   -> (time stamps = 120, number of neurons, number of trials)\n",
    "data_corr = [d[0] for d in data['zscore1'][0,0]]\n",
    "data_pert = [d[0] for d in data['zscore2'][0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81eab699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('./data_raw.mat')['dataraw']['masterlist'][0,0]\n",
    "# data structure:\n",
    "# -> (number of birds = 6, 2 conditions = pre / post deafening)\n",
    "#   -> Only [3,0] is useful; col 0 = singing\n",
    "#      row 0 = denoised calcium signal\n",
    "#      row 1 = deconvolved spikes\n",
    "#      row 2 = raw calcium \n",
    "#      row 3 = zscored calcium \n",
    "#      the rest are blank\n",
    "#     -> (time stamps = 120, number of neurons, number of trials)\n",
    "idx = loadmat('./data_raw.mat')['dataraw']['neuronvec'][0,0]\n",
    "# idx structure:\n",
    "# -> (number of birds = 6, 1)\n",
    "#   -> (registered neuron indices, 2 conditions = pre / post deafening)\n",
    "data_predeaf, data_postdeaf = [], []\n",
    "for i in range(data.shape[0]):\n",
    "    data_predeaf.append(data[i,0][3,0][:,idx[i,0][:,0]-1,:]) \n",
    "    data_postdeaf.append(data[i,1][3,0][:,idx[i,0][:,1]-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7a2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpre = 6\n",
    "t0 = 60 # song onset\n",
    "t1 = t0 + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4804fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_activity(data):\n",
    "    signals_mean, signals_se, mean_activity, se_activity = [], [], [], []   \n",
    "    for signal in data:\n",
    "        # (time, neurons, trials)\n",
    "        signal = signal - signal[t0-tpre:t0].mean(axis=0, keepdims=True)\n",
    "\n",
    "        time_avg = signal[t0:t1].mean(axis=0)\n",
    "        \n",
    "        signals_mean.append(signal[t0-tpre:t1].mean(axis=-1))\n",
    "        signals_se.append(signal[t0-tpre:t1].std(axis=-1) / np.sqrt(signal.shape[-1]))\n",
    "        mean_activity.append(time_avg.mean(axis=1))\n",
    "        se_activity.append(time_avg.std(axis=1) / np.sqrt(time_avg.shape[1]))\n",
    "        \n",
    "    signals_mean = np.hstack(signals_mean)\n",
    "    signals_se = np.hstack(signals_se)\n",
    "    mean_activity, se_activity = np.hstack(mean_activity), np.hstack(se_activity)\n",
    "    return signals_mean, signals_se, mean_activity, se_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec6245b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first two: mean and se of trial-averaged activity\n",
    "# last two: mean and se of trial-averaged and window-averaged activity\n",
    "signal_mean_corr, signal_se_corr, mean_corr, se_corr = processed_activity(data_corr)\n",
    "signal_mean_pert, signal_se_pert, mean_pert, se_pert = processed_activity(data_pert)\n",
    "signal_mean_predeaf, signal_se_predeaf, mean_predeaf, se_predeaf = processed_activity(data_predeaf)\n",
    "signal_mean_postdeaf, signal_se_postdeaf, mean_postdeaf, se_postdeaf = processed_activity(data_postdeaf)\n",
    "\n",
    "to_save = dict(\n",
    "    signal_mean_corr=signal_mean_corr, signal_se_corr=signal_se_corr, \n",
    "    mean_corr=mean_corr, se_corr=se_corr,\n",
    "    signal_mean_pert=signal_mean_pert, signal_se_pert=signal_se_pert, \n",
    "    mean_pert=mean_pert, se_pert=se_pert,\n",
    "    signal_mean_predeaf=signal_mean_predeaf, signal_se_predeaf=signal_se_predeaf,\n",
    "    mean_predeaf=mean_predeaf, se_predeaf=se_predeaf,\n",
    "    signal_mean_postdeaf=signal_mean_postdeaf, signal_se_postdeaf=signal_se_postdeaf,\n",
    "    mean_postdeaf=mean_postdeaf, se_postdeaf=se_postdeaf\n",
    ")\n",
    "\n",
    "for k, v in to_save.items():\n",
    "    np.savetxt(f'./processed_data/{k}.csv', v, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df605c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
